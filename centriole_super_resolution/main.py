import os
import apply_transformation as aptf
import paths_definitions as pth
import inference as inf

tile_size = 312
import matplotlib.pyplot as plt



def train(HR_folder, LR_folder, model_name, **kwargs):

    cmd = f'python3 {pth.train_code_location} --lr_folder {LR_folder} --hr_folder {HR_folder} --save_name {model_name}'

    for arg_name in kwargs.keys():
        arg_value = kwargs.get(arg_name)
        if not isinstance(arg_value, bool):
            cmd +=  f' --{arg_name} {arg_value}'
        else:
            if arg_value:
                cmd += f' --{arg_name}'

    os.system(cmd)


if __name__ == "__main__":
    """generates LR images by applying convolution resing and normalization, then trains a model with the code train.py
    and save it. Finally, tests the model with the code inference.py and save the results
    Choose parameters here"""

    spots = True #if true, LR_folder is not generated from HR_folder but from spot_fold (its time consuming to add
    #spots so it is better to do it only once

    HR_folder = f'{pth.training_sets}/HR_n/deconv/c2' #path of the HR folder, should be split in train/valid
    spot_fold = f'{pth.training_sets}/HR_spots/deconv/c2'
    HR_spots = spot_fold if spots else HR_folder #folder from which LR folder is generated by applying convolution,
    test_images_path = f'{pth.wide_field_3D}/deconv/c2' #images on which prediction is made

    print('HR_spots',HR_spots)

    p = 1 #proportion of training set used

    sigma = 4 #standard deviation of convolution
    #upscale = int(sigma*np.sqrt(2))
    upscale = 2 #ratio HRshape/LRshape
    size = 312 #fatsai applies rescaling so that HR images have a shape of (size, size). This parameter is recommanded to
    #be set to the size of images in HR_folder (rescaling will have no effect)
    noise = False #use noise in degradation model

    model = 'wnresnet' #possibilities : rrdb,rrdb2,wnresnet,srfbn,rcan,rdn, choose also hyper-parameters of architecture
    #in train.py

    lr = 10**-4 #learning rate
    nb_epoch = 1
    max_zoom = 2. #zoom is used in data augmentation, maximum value of this zoom
    bs = 8 #batch size

    alpha = 1 #power in L_alpha loss (ex : alpha = 1, L1 loss. alpha=2, L2_loss)
    feature_loss = False
    betha = 1 #power in feature loss
    nb_layer_vgg = 9 #nb layer to extract feature (if feature loss)
    prop = 1 #proportion of feature loss used (if feature_loss = True)

    test_wide_field = True #make prediction on wide_field data
    test_valid = True #make prediction on validation data
    skip_train = False #directly test the model without training (the model defined by model_name should already exists)

    # defines the name of the model with the parameters used
    str_p = '' if p == 1 else f'prop_used_{p}'
    raw = False
    str_raw = '_raw' if raw else ''
    str_loss = f'l{alpha}_loss' if not feature_loss else f'feat_loss_vgg{nb_layer_vgg}'
    str_spot = f'_sans_spots' if not spots else ''
    #str_scale = f'_scale_{int(1/scale)}' if scale != 0.5 else ''
    model_name = f'{model}_sig{sigma}_{str_loss}{str_raw}{str_spot}_{size}'
    # model  will be saved in location {models}/{model_name}.pkl

    scale = 1 / upscale
    str_tile_sz = '' if size == 312 else f'_tile_sz_{size//2}'
    LR_folder = f'{pth.training_sets}/LR_{sigma}{str_tile_sz}'

    if noise:
        LR_folder += '_noise'
    if upscale != 2:
        LR_folder += f'_scale_{upscale}'
    if not skip_train:
        """generate LR folder from folder HR_spots by convolving, resizing and normalize from this folder
            Then train a model : maps the LR folder generated with HR_folder"""
        print(f'apply degradation model conv resize norm to {HR_spots}')
        aptf.conv_resize_norm(HR_spots, LR_folder, sigma, scale, noise=noise)
        print(f'degraded images generated at location {LR_folder}')
        print(f' maps {LR_folder} with {HR_folder}')
        train(HR_folder, LR_folder, model_name, scale=upscale, size=size, model=model, epochs=nb_epoch, max_rotate=20,
              bs=bs, lr=lr, feat_loss=feature_loss, alpha=alpha, max_zoom=max_zoom, prop=prop,
              nb_layer_vgg=nb_layer_vgg, betha=betha, p=p)
    topaz = False #if true prediction is made only on patches centered on centrioles, other pixels are set to 0
    topaz2 = False #if true generate as many output images as centrioles in input image (one for each)
    center_txt = f'{pth.myHome}/center_particles_wide_field_resized.txt' #txt file containing centers of centrioles (of wide field_images)
    # used if topaz or topaz2

    if test_valid or test_wide_field:
        inf.inference(model_name, test_images_path, hr_folder=HR_folder, lr_folder=LR_folder, scale=upscale,
                      test_on_training=test_valid, test_on_wide_field=test_wide_field, topaz=topaz,
                      topaz2=topaz2, center_txt=center_txt, size=size // upscale)


